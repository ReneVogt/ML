{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import connect4\n",
    "importlib.reload(connect4);\n",
    "from connect4 import Connect4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hyper parameters\n",
    "# \n",
    "alpha = 0.0005\n",
    "gamma = 0.9\n",
    "entropy_coefficient = 0.1\n",
    "stabilizer = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create the model and optimizer\n",
    "# \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(126, 294),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(294, 294),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(294, 7),\n",
    "    nn.Softmax(dim=-1))\n",
    "games = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load model from checkpoint\n",
    "#\n",
    "games = 750000\n",
    "cp = torch.load(f'connect4-{games}.nn');\n",
    "model.load_state_dict(cp['model_state_dict']);\n",
    "optimizer.load_state_dict(cp['optimizer_state_dict']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def checkpoint(step):\n",
    "    train = model.training\n",
    "    if train: model.eval();\n",
    "    print(f\"{step}: checkpoint...\")\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, f'connect4-{step}.nn');\n",
    "\n",
    "    dummy_input = Connect4().state\n",
    "    torch.onnx.export(model, dummy_input, f\"connect4.onnx\", );\n",
    "\n",
    "    print(f\"{step}: checkpoint saved.\")\n",
    "    if train: model.train();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TRAINING\n",
    "#\n",
    "log_interval = 10000\n",
    "validation_interval = 50000\n",
    "validation_games = 5000\n",
    "checkpoint_interval = 50000\n",
    "losses = []\n",
    "\n",
    "for _ in range(250000):\n",
    "    env = Connect4()\n",
    "    games += 1    \n",
    "\n",
    "    episode = connect4.generateEpisode(model)\n",
    "\n",
    "    returns = []\n",
    "    R = 0\n",
    "    for _, _, reward in reversed(episode):\n",
    "        R = reward - gamma * R\n",
    "        returns.insert(0, R)\n",
    "    \n",
    "    states, actions, rewards = zip(*episode)\n",
    "    states_tensor = torch.stack(states)         # [t,126]\n",
    "    actions_tensor = torch.LongTensor(actions)  # [t]\n",
    "    returns_tensor = torch.FloatTensor(returns) # [t]\n",
    "\n",
    "    # normalize returns\n",
    "    returns_tensor = (returns_tensor - returns_tensor.mean()) / (returns_tensor.std() + stabilizer)\n",
    "\n",
    "    baseline = returns_tensor.mean().detach()\n",
    "\n",
    "    model.train()\n",
    "    action_probs = model(states_tensor) # [t, 7]\n",
    "    chosen_probs = action_probs.gather(1, actions_tensor.unsqueeze(1)) # unsqueeze(1) -> [t,1]\n",
    "    chosen_probs += stabilizer\n",
    "    log_probs = torch.log(chosen_probs).squeeze() # [t,1] -> squeeze -> [t]\n",
    "\n",
    "    policy_loss = -(returns_tensor - baseline) * log_probs\n",
    "\n",
    "    entropy = -torch.sum(action_probs * torch.log(action_probs), dim=1)\n",
    "\n",
    "    loss = policy_loss.mean() - entropy_coefficient * entropy.mean()\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if games % log_interval == 0:\n",
    "        print(f'{games}: average loss: {sum(losses)/len(losses)}')\n",
    "        losses = []\n",
    "\n",
    "    if games % checkpoint_interval == 0:\n",
    "        checkpoint(games)\n",
    "    if games % validation_interval == 0:\n",
    "        print(f'{games}: validating...')\n",
    "        connect4.validate(model, validation_games)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect4.validate(model, 10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 126-294-ReLU-294-ReLU-7\n",
    "- alpha: 0.0005\n",
    "- gamma: 0.9\n",
    "- entropy_coefficient: 0.05 (0.1 since 750000)\n",
    "\n",
    "#### Results\n",
    "|Games|Loss|Red|Yellow||\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|550000| -0.1869731299161911 | 94.10 0.00 5.90 | 86.04 0.02 13.94|\n",
    "|600000| -0.18033885388188065 | 93.48 0.02 6.50 | 87.14 0.02 12.84|\n",
    "|650000| -0.1750567243643105 | 94.20 0.00 5.80 | 86.08 0.00 13.92 |\n",
    "|700000| -0.1734218504589051 | 93.38 0.00 6.62 | 86.76 0.04 13.20 |\n",
    "|750000| -0.17464535967707634 |96.34 0.02 3.64|86.84 0.04 13.12|\n",
    "|800000|-0.23563749998174607|96.24 0.00 3.76|90.04 0.00 9.96| _doubled entropy coefficient to 0.1_ |\n",
    "|850000|-0.24879778488092125|97.34 0.00 2.66|92.16 0.00 7.84|\n",
    "|900000|-0.24367169531211258|98.50 0.00 1.50|92.62 0.00 7.38|\n",
    "|950000|-0.25199465897753837|97.78 0.00 2.22|92.62 0.02 7.36|\n",
    "|1000000|-0.25451473476402464|98.24 0.00 1.76|92.98 0.04 6.98|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
