{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import datetime\n",
    "\n",
    "import torch as T\n",
    "\n",
    "from board import Connect4Board\n",
    "from board2dqn import createStateTensor\n",
    "from agent import Connect4Agent, calculateReward\n",
    "from validation import validate\n",
    "from dqn import exportOnnx\n",
    "\n",
    "def log(message):\n",
    "    print(f\"[{datetime.datetime.now().strftime('%H:%M:%S')}] {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hyper parameters\n",
    "# \n",
    "lr = 0.05\n",
    "gamma = 0.9\n",
    "epsilon = 0.01\n",
    "eps_min = 0.1\n",
    "eps_dec = 0\n",
    "batch_count = 4\n",
    "batch_size = 512\n",
    "memory_size = 64000\n",
    "\n",
    "target_update_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Connect4Agent(\n",
    "    lr = lr, \n",
    "    epsilon = epsilon, \n",
    "    epsilon_end = eps_min, \n",
    "    epsilon_decay = eps_dec,\n",
    "    batch_size = batch_size, \n",
    "    batch_count = batch_count,\n",
    "    memory_size = memory_size,\n",
    "    gamma = gamma,\n",
    "    targetUpdateInterval=target_update_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint connect4-d.\n"
     ]
    }
   ],
   "source": [
    "# load agent from checkpoint\n",
    "agent.loadCheckpoint(f'connect4-d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:43] Starting training for 20000 games.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renev\\AppData\\Local\\Temp\\ipykernel_18364\\2078915068.py:29: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  validMovesMask = T.tensor([env.is_valid(a) for a in range(7)], dtype=bool)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     25\u001b[0m validMoves \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39mis_valid(a)]\n\u001b[1;32m---> 26\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrainingAction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidMoves\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m env\u001b[38;5;241m.\u001b[39mmove(action)\n\u001b[0;32m     28\u001b[0m next_state \u001b[38;5;241m=\u001b[39m createStateTensor(env)\n",
      "File \u001b[1;32mc:\\Users\\renev\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\René\\Sourcen\\ML\\src\\dev\\connect4\\agent.py:77\u001b[0m, in \u001b[0;36mConnect4Agent.getTrainingAction\u001b[1;34m(self, state, validMoves)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validMoves[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetBestAction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluationModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidMoves\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(validMoves)\n",
      "File \u001b[1;32mc:\\Users\\renev\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\René\\Sourcen\\ML\\src\\dev\\connect4\\..\\connect4\\board2dqn.py:22\u001b[0m, in \u001b[0;36mgetBestAction\u001b[1;34m(model, state, validMoves)\u001b[0m\n\u001b[0;32m     20\u001b[0m training \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtraining\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 22\u001b[0m qs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([a \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m validMoves], key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: qs[x])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# TRAINING\n",
    "#\n",
    "gamesToGo = 20000\n",
    "\n",
    "log_interval = 5000\n",
    "\n",
    "validation_interval = 10000\n",
    "validation_games = 1000\n",
    "omega = 0\n",
    "\n",
    "lastLoggedGame = 0\n",
    "games = set()\n",
    "allGames = set()\n",
    "\n",
    "log(f\"Starting training for {gamesToGo} games.\")\n",
    "\n",
    "for game in range(1, gamesToGo+1):\n",
    "    env = Connect4Board()\n",
    "        \n",
    "    next_state = createStateTensor(env)\n",
    "    \n",
    "    while not env.Finished:\n",
    "        state = next_state\n",
    "        validMoves = [a for a in range(7) if env.is_valid(a)]\n",
    "        action = agent.getTrainingAction(state, validMoves)\n",
    "        env.move(action)\n",
    "        next_state = createStateTensor(env)\n",
    "        validMovesMask = T.tensor([env.is_valid(a) for a in range(7)], dtype=bool)\n",
    "        reward = calculateReward(env)\n",
    "        agent.store_transition(state, action, next_state, validMovesMask, env.Finished, reward)\n",
    "\n",
    "    games.add(env.gameKey)\n",
    "    allGames.add(env.gameKey)\n",
    "    agent.learn()\n",
    "\n",
    "    if game % log_interval == 0:\n",
    "        log(f'{game} games, div: {100*len(games)/(game+1-lastLoggedGame):.2f} / {100*len(allGames)/(game+1):.2f}')\n",
    "        games.clear()\n",
    "        lastLoggedGame = game\n",
    "        agent.printStats()\n",
    "    if game % validation_interval == 0:\n",
    "        agent.saveCheckpoint(f'connect4-{game}')\n",
    "        log(f'Validation:')\n",
    "        validate(agent, validation_games, omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a: 0.01042946996674873 100.00 99.80  \n",
    "b: 0.0.0030970556917702197 99.7 100  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation with 0% random moves for 1000 games per player.\n",
      "Player 1: 995 won, 4 lost, 1 draws -> 99.50%, div: 82.80%\n",
      "Player 2: 999 won, 1 lost, 0 draws -> 99.90%, div: 90.70%\n"
     ]
    }
   ],
   "source": [
    "validate(agent.evaluationModel, 1000, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
