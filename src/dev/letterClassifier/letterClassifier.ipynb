{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import cnn\n",
    "import training\n",
    "importlib.reload(cnn)\n",
    "importlib.reload(training)\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as o\n",
    "import torch.optim.lr_scheduler as s\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669642 parameters on 'cuda'.\n"
     ]
    }
   ],
   "source": [
    "device = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = cnn.LetterClassifierCnn()\n",
    "model.to(device)\n",
    "print(f\"{sum(p.numel() for p in model.parameters() if p.requires_grad)} parameters on '{device}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = o.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = s.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 124800 Testing samples: 20800\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_dataset = T.load('train.pt')\n",
    "test_dataset = T.load('test.pt')\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f'Training samples: {len(train_dataset)} Testing samples: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training loss: 0.4328 accuracy: 86.42%\n",
      "Evaluation loss: 0.2541 accuracy: 91.64%\n",
      "Epoch: 2\n",
      "Training loss: 0.2047 accuracy: 93.13%\n",
      "Evaluation loss: 0.1997 accuracy: 93.41%\n",
      "Epoch: 3\n",
      "Training loss: 0.1644 accuracy: 94.24%\n",
      "Evaluation loss: 0.1988 accuracy: 93.42%\n",
      "Epoch: 4\n",
      "Training loss: 0.1394 accuracy: 94.96%\n",
      "Evaluation loss: 0.1830 accuracy: 93.96%\n",
      "Epoch: 5\n",
      "Training loss: 0.1204 accuracy: 95.48%\n",
      "Evaluation loss: 0.1927 accuracy: 93.72%\n",
      "Epoch: 6\n",
      "Training loss: 0.1053 accuracy: 95.98%\n",
      "Evaluation loss: 0.1962 accuracy: 93.87%\n",
      "Epoch: 7\n",
      "Training loss: 0.0921 accuracy: 96.37%\n",
      "Evaluation loss: 0.2086 accuracy: 93.72%\n",
      "Epoch: 8\n",
      "Training loss: 0.0805 accuracy: 96.79%\n",
      "Evaluation loss: 0.2198 accuracy: 93.56%\n",
      "Epoch: 9\n",
      "Training loss: 0.0528 accuracy: 97.80%\n",
      "Evaluation loss: 0.2111 accuracy: 94.12%\n",
      "Epoch: 10\n",
      "Training loss: 0.0458 accuracy: 98.03%\n",
      "Evaluation loss: 0.2204 accuracy: 94.20%\n",
      "Epoch: 11\n",
      "Training loss: 0.0426 accuracy: 98.18%\n",
      "Evaluation loss: 0.2271 accuracy: 94.20%\n",
      "Epoch: 12\n",
      "Training loss: 0.0402 accuracy: 98.28%\n",
      "Evaluation loss: 0.2376 accuracy: 94.10%\n",
      "Epoch: 13\n",
      "Training loss: 0.0368 accuracy: 98.43%\n",
      "Evaluation loss: 0.2389 accuracy: 94.16%\n",
      "Epoch: 14\n",
      "Training loss: 0.0363 accuracy: 98.45%\n",
      "Evaluation loss: 0.2414 accuracy: 94.18%\n",
      "Epoch: 15\n",
      "Training loss: 0.0359 accuracy: 98.47%\n",
      "Evaluation loss: 0.2437 accuracy: 94.17%\n",
      "Epoch: 16\n",
      "Training loss: 0.0357 accuracy: 98.47%\n",
      "Evaluation loss: 0.2456 accuracy: 94.20%\n",
      "Epoch: 17\n",
      "Training loss: 0.0352 accuracy: 98.50%\n",
      "Evaluation loss: 0.2459 accuracy: 94.18%\n",
      "Epoch: 18\n",
      "Training loss: 0.0352 accuracy: 98.51%\n",
      "Evaluation loss: 0.2462 accuracy: 94.19%\n",
      "Epoch: 19\n",
      "Training loss: 0.0352 accuracy: 98.51%\n",
      "Evaluation loss: 0.2464 accuracy: 94.20%\n",
      "Epoch: 20\n",
      "Training loss: 0.0351 accuracy: 98.50%\n",
      "Evaluation loss: 0.2466 accuracy: 94.19%\n",
      "Epoch: 21\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 22\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 23\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 24\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 25\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 26\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 27\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 28\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 29\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 30\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 31\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n",
      "Epoch: 32\n",
      "Training loss: 0.0351 accuracy: 98.51%\n",
      "Evaluation loss: 0.2467 accuracy: 94.19%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(32):\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    loss, accuracy = training.train(model, train_loader, device, optimizer)\n",
    "    print(f'Training loss: {loss:.4f} accuracy: {accuracy:.2f}%')\n",
    "    loss, accuracy = training.evaluate(model, test_loader, device)\n",
    "    print(f'Evaluation loss: {loss:.4f} accuracy: {accuracy:.2f}%')\n",
    "    scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T.save({'model_state_dict': model.state_dict()}, 'letterClassification.nn');\n",
    "\n",
    "model.eval()\n",
    "model.to(T.device('cpu'))\n",
    "example_input = T.randn(1, 1, 28, 28)  # Adjust the input size as per your model\n",
    "#example_input = example_input.to(device)\n",
    "scripted_model = T.jit.trace(model, example_input)\n",
    "\n",
    "scripted_model.save(\"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "# Define preprocessing transforms\n",
    "transform = Compose([\n",
    "    ToTensor(),  # Convert image to PyTorch tensor\n",
    "    Normalize((0.5,), (0.5,))  # Normalize pixel values to [-1, 1]\n",
    "])\n",
    "\n",
    "# Download and load the dataset\n",
    "train_dataset = EMNIST(root='../../../../DataSets', split='letters', train=True, download=False, transform=transform)\n",
    "test_dataset = EMNIST(root='../../../../DataSets', split='letters', train=False, download=False, transform=transform)\n",
    "\n",
    "T.save(train_dataset, 'train.pt')\n",
    "T.save(test_dataset, 'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count = 0\n",
    "for image, label in train_dataset:\n",
    "    if label != 11:\n",
    "        continue\n",
    "    count += 1\n",
    "\n",
    "    img = image.numpy()\n",
    "\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    if count == 10:\n",
    "        break;\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
